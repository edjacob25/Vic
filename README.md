# VIC
This is an implementation of the Validation Index using supervised Classifiers algorithm, described in *Cluster validation using an ensemble of supervised classifiers.* by Jorge Rodríguez, Miguel Medina-Pérez, Andrés Gutiérrez-Rodríguez, Raúl Monroy, and Hugo Terashima-Marín.

## Environment
We use Python 3.7 characteristics, so it is necessary to have it installed in order to run these files.

The required libraries are specified in the `requirements.txt` file, which can be simply installed by doing
```shell script
pip install -r requirements.txt
```

The use of virtual environments is highly recommended.

## Included Files

- `canonical_vic.py` - A less specialized version which represents the whole VIC implementation, including splitting the dataset into parts sing KMeans
- `common.py` - Common functions used in the other scripts
- `config.example.ini` - A configuration file, including weka paths and the number of processors that will be used in the parallel implementations
- `requirements.txt` - Libraries required to run these files
- `vic.py` - Our own VIC implementation, it scans a directory for the CSV files generated by `create_clusters` and uses a plethora of classifiers to get the best AUC, it is specific to this assignment   
## How to run
Once the libraries are installed, we need to create the config file and fill it. You can achieve this by renaming `config.example.ini` to `config.ini` and modifying the values. This can be done by:
```shell script
cd folder/with/code
mv config.example.ini config.ini
nano config.ini 
```
After that, it is pretty easy to replicate our work by issuing the following commands:
```shell script
python vic.py Data/Partitions # This command calculates the best AUC for all the CSV files in Data/Partitions directory and outputs which were the best partitions
python canonical_vic.py Data/initial_data.csv # OPTIONAL: If you want to apply the VIC and creating the partitions on the fly using KMeans   
```
## How does the parallelization works
We use the Python library for multithreading and simply create a thread pool using the configured number of processes. Then, for each file in the directory, we use one of the threads open and inside of it, we do a 10-CrossFold Validation with all of the classifiers, choosing the best one and selecting it for that file.

In the case of `canonical_vic` we adopt a similar strategy, only changing which work is actually split, Instead of doing the work for each file in a thread, we evaluate a classifier in each thread.  
